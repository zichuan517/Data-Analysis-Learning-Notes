# 01  线性回归

### 1.相关系数：衡量已知数据的相关性

$$
r = \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^n (x_i - \bar{x})^2 \sum_{i=1}^n (y_i - \bar{y})^2}}
$$


### 2.线性回归：预测未知数据

$$
y=ax+b 
$$

$$
a=\frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2 }
$$

$$
b=\bar{y}-a\bar{x}
$$

### 3.多元线性回归

$$
S(\boldsymbol{\beta}) = \sum_{i=1}^n (y_i - \hat{y}_i)^2 = (\mathbf{y} - \mathbf{X}\boldsymbol{\beta})^T(\mathbf{y} - \mathbf{X}\boldsymbol{\beta})
$$

$$
\mathbf{X}^T\mathbf{X}\hat{\boldsymbol{\beta}} = \mathbf{X}^T\mathbf{y}
$$

$$
\hat{\boldsymbol{\beta}} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y}
$$

### 4.将分类变量纳入线性方程的自变量

引入虚拟变量（0，1）

若一个分类指标中有N个分类变量，则引入**N-1**个虚拟变量

这是因为当我们知道了前N-1个变量的值之后，可以直接推到出第N个的值

 引入 N-1 个虚拟变量而不是 N 个是由于**完全多重共线性**问题 

**虚拟变量陷阱**（Dummy Variable Trap）：

若引入 N 个虚拟变量，会产生完全多重共线性，导致矩阵不可逆，无法求解回归系数。

假设有一个分类变量有 3 个类别（A, B, C），我们创建 3 个虚拟变量：

```
D1 = 1 if A, 0 otherwise
D2 = 1 if B, 0 otherwise  
D3 = 1 if C, 0 otherwise
```

对于每个观测值，都有：

```
D1 + D2 + D3 = 1
```

这就产生了 **完全线性关系** ：

```
D1 + D2 + D3 = \text{截距列}
```

### 5.删减自变量

（1）所以在建立线性回归模型前，先进行相关性分析，考察自变量之间的相关性）

若r>0.8，可以考虑移除一个变量，再做回归分析

（2）p值大，自变量对因变量影响显著，保留

p值小，自变量对因变量影响不显著，移除

### 6.决定系数$R^2$评估拟合度

$$
R^2 = 1 - \frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{\sum_{i=1}^n (y_i - \bar{y})^2}
$$


$R^2$越接近1，说明模型的预测值和实际观测值相差越大

$R^2$越接近0，说明模型的预测值和实际观测值相差越小
